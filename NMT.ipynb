{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_to_idx_english.json','r') as f:\n",
    "    word_to_idx_english=json.load(f)\n",
    "with open('word_to_idx_hindi.json','r') as f:\n",
    "    word_to_idx_hindi=json.load(f)\n",
    "with open('idx_to_word_english.json','r') as f:\n",
    "    idx_to_word_english=json.load(f)\n",
    "with open('idx_to_word_hindi.json','r') as f:\n",
    "    idx_to_word_hindi=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 30\n"
     ]
    }
   ],
   "source": [
    "max_length_eng=0\n",
    "for x in df['english_sentence']:\n",
    "    max_length_eng=max(max_length_eng,len(str(x).split()))\n",
    "max_length_hindi=0\n",
    "for x in df['hindi_sentence']:\n",
    "    max_length_hindi=max(max_length_hindi,len(str(x).split()))\n",
    "print(max_length_eng,max_length_hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(word_to_idx_english) \n",
    "num_decoder_tokens = len(word_to_idx_hindi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens+=1\n",
    "#zero padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df['english_sentence'], df['hindi_sentence']\n",
    "x, x_test, y, y_test = train_test_split(x, y, test_size = 0.2,random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataGenerator(x,y,batch_size=128):\n",
    "    for j in range(0,len(x),batch_size):\n",
    "        encoder_input=np.zeros((batch_size,max_length_eng),dtype='float32')\n",
    "        decoder_input=np.zeros((batch_size,max_length_hindi),dtype='float32')\n",
    "        decoder_output=np.zeros((batch_size,max_length_hindi,num_decoder_tokens),dtype='float32')\n",
    "        for i, (eng,hindi) in enumerate(zip(x[j:j+batch_size], y[j:j+batch_size])):\n",
    "            for idx,w in enumerate(eng.split()):\n",
    "                encoder_input[i,idx]=word_to_idx_english[w]\n",
    "            for idx,w in enumerate(hindi.split()):\n",
    "                if idx<len(hindi.split())-1:\n",
    "                    decoder_input[i,idx]=word_to_idx_hindi[w]\n",
    "                if idx>0:\n",
    "                    decoder_output[i,idx-1,word_to_idx_hindi[w]]=1\n",
    "        yield ([encoder_input,decoder_input],decoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As stated in the keras documentation you can use 3D (or higher rank) data as input for a \n",
    "# Dense layer but the input gets flattened first:\n",
    "# Note: if the input to the layer has a rank greater than 2, then it is flattened prior to \n",
    "# the initial dot product with kernel.This means that if your input has shape \n",
    "# (batch_size, sequence_length, dim), then the dense layer will first flatten your data to\n",
    "# shape (batch_size * sequence_length, dim) and then apply a dense layer as usual. The output\n",
    "# will have shape (batch_size, sequence_length, hidden_units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
